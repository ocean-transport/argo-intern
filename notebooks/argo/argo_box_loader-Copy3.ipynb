{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argo File Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with newest snapshot\n",
    "# try with ftp that gmaze used in issue, probably going to be really slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import gsw\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from importlib import reload\n",
    "from cmocean import cm as cmo\n",
    "import xrft\n",
    "import pandas as pd\n",
    "import argopy\n",
    "from argopy import DataFetcher\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argopy: 1.0.0, xarray: 2024.2.0, dask: 2024.10.0\n"
     ]
    }
   ],
   "source": [
    "print('argopy: {}, xarray: {}, dask: {}'.format(argopy.__version__, xr.__version__, dask.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home.ufs/amf2288/argo-intern/funcs')\n",
    "import density_funcs as df\n",
    "import EV_funcs as ef\n",
    "import filt_funcs as ff\n",
    "import plot_funcs as pf\n",
    "import processing_funcs as prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'processing_funcs' from '/home/amf2288/argo-intern/funcs/processing_funcs.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(df)\n",
    "reload(ef)\n",
    "reload(ff)\n",
    "reload(pf)\n",
    "#reload(mf)\n",
    "reload(prf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing parallel loading with dask client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client= Client(processes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = [-27.5, -22.5, -5, 5, 0, 2001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with argopy.set_options(parallel=client):\n",
    "    f = DataFetcher(src='gdac', ftp='/swot/SUM05/dbalwada/Argo_sync', progress=True).region(box)\n",
    "    print('%i chunks to process' % len(f.uri))\n",
    "    print(f)\n",
    "    ds = f.load().data#.to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay the process is running on multiple GPUs, in this case 10-12 machines. However, obviously there are a ton of error messages---I'm not really sure what's going wrong. The box I've started with is really small, so I don't think there should be a memory error. Not sure where to go from here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load by box (coordinate: N_PROF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box=[lon_min,lon_max,lat_min,lat_max,depth_min,depth_max]\n",
    "box_atl = [-25,-20,-70,70,0,2001]\n",
    "box_pac = [-180,-175,-70,70,0,2001]\n",
    "box_watl = [-60,-55,10,45,0,2001]\n",
    "box_wpac = [150,155,-5,50,0,2001]\n",
    "box_wind = [60,65,-65,25,0,2001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NW = [-180,0,0,90,0,2001]\n",
    "NE = [0,180,-90,0,0,2001]\n",
    "SW = [-180,0,-90,0,0,2001]\n",
    "SE = [0,180,0,90,0,2001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1 = [-180,-90,  0,90,0,2001]\n",
    "box2 = [- 90,  0,  0,90,0,2001]\n",
    "box3 = [   0, 90,  0,90,0,2001]\n",
    "box4 = [  90,180,  0,90,0,2001]\n",
    "box5 = [-180,-90,-90, 0,0,2001]\n",
    "box6 = [- 90,  0,-90, 0,0,2001]\n",
    "box7 = [   0, 90,-90, 0,0,2001]\n",
    "box8 = [  90,180,-90, 0,0,2001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pf.plot_box([NW,NE,SW,SE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading points complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home.ufs/amf2288/mambaforge-pypy3/envs/Argo_Nov_24/lib/python3.12/site-packages/argopy/data_fetchers/gdac_data.py:331: UserWarning: Found more than 50 files to load, this may take a while to process sequentially ! Consider using another data source (eg: 'erddap') or the 'parallel=True' option to improve processing time.\n",
      "  warnings.warn(\n",
      " 22%|██▏       | 740/3366 [34:10<1:09:27,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oops! <class 'ValueError'> occurred.\n",
      "Fail to cast: SCIENTIFIC_CALIB_DATE \n",
      "Encountered unique values: [b'-             ' b'20070325140000' b'20070330095000' b'20110930175000'\n",
      " b'20110930175100' b'20110930175200' b'20150728150000' b'20150728150100'\n",
      " b'20150728150200' b'20150728150300' b'20150728150400' b'20150728150500'\n",
      " b'20150728150600' b'20150728150700' b'20150728150800' b'20150728150900'\n",
      " b'20150728151000' b'20150728151100' b'20150728151200' b'20150728151300'\n",
      " b'20150728151400' b'20150728151500' b'20150728151600' b'20150728151700'\n",
      " b'20150728151800' b'20150728151900' b'20150728152000' b'20150728152100'\n",
      " b'20150728152200' b'20150728152300' b'20150728152400' b'20150728152500'\n",
      " b'20150728152600' b'20150728152700' b'20150728152800' b'20150728152900'\n",
      " b'20150728153000' b'20150728153100' b'20150728153200' b'20150728153300'\n",
      " b'20150728153400' b'20150728153500']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3366/3366 [2:35:05<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to xarray complete\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"No variable named 'PSAL'. Variables on the dataset include ['CYCLE_NUMBER', 'DATA_MODE', 'DIRECTION', 'PLATFORM_NUMBER', 'POSITION_QC', ..., 'TIME_QC', 'TIME', 'LATITUDE', 'LONGITUDE', 'N_POINTS']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/mambaforge-pypy3/envs/Argo_Nov_24/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1446\u001b[0m             \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_virtual_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PSAL'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/mambaforge-pypy3/envs/Argo_Nov_24/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1545\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_dataarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1547\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m   1548\u001b[0m                     \u001b[0;34mf\"\u001b[0m\u001b[0;34mNo variable named \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m!\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m. Variables on the dataset include \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mshorten_list_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge-pypy3/envs/Argo_Nov_24/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1446\u001b[0m             \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_virtual_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge-pypy3/envs/Argo_Nov_24/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(variables, key, dim_sizes)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0msplit_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_key\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PSAL'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3003/1584339238.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/amf2288/argo-intern/funcs/processing_funcs.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(box, interp_step)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_xarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"to xarray complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteos10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SA\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SIG0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoint2profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"point to profile complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge-pypy3/envs/Argo_Nov_24/lib/python3.12/site-packages/argopy/xarray.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, vlist, inplace)\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0mto_profile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m             \u001b[0mthis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile2point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;31m# Get base variables as numpy arrays:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1366\u001b[0;31m         \u001b[0mpsal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PSAL\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1367\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TEMP\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0mpres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PRES\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mlon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"LONGITUDE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge-pypy3/envs/Argo_Nov_24/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_dataarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1547\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m   1548\u001b[0m                     \u001b[0;34mf\"\u001b[0m\u001b[0;34mNo variable named \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m!\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m. Variables on the dataset include \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mshorten_list_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m                 \u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"No variable named 'PSAL'. Variables on the dataset include ['CYCLE_NUMBER', 'DATA_MODE', 'DIRECTION', 'PLATFORM_NUMBER', 'POSITION_QC', ..., 'TIME_QC', 'TIME', 'LATITUDE', 'LONGITUDE', 'N_POINTS']\""
     ]
    }
   ],
   "source": [
    "ds = prf.get_box(box4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.assign_attrs({\"Fetched_uri\":''})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(\"/swot/SUM05/amf2288/sync-boxes/lon:({},{})_lat:({},{})_ds_z.nc\".format(NW[0],NW[1],NW[2],NW[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_1x = [-10,0,-10,0,0,2000]   #error\n",
    "box_1y = [-10,0,-20,-10,0,2000] #done\n",
    "box_1z = [-10,0,-30,-20,0,2000] #done\n",
    "box_1a = [-10,0,-40,-30,0,2000] #done\n",
    "box_1b = [-10,0,-50,-40,0,2000] #done\n",
    "box_1c = [-10,0,-60,-50,0,2000] #done\n",
    "box_1d = [-10,0,-70,-60,0,2000] #done\n",
    "box_long=[-10,-8,-70,-10,0,2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.plot_box([box_1x,box_1y,box_1z,box_1a,box_1b,box_1c,box_1d,box_long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_z=ff.get_box(box_long,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['N_PROF'].attrs = {'name':'Fetched Profile Number'}\n",
    "ds['PRES_INTERPOLATED'].attrs = {'name':'Interpolated Pressure', 'units':'dbar', 'notes':'interpolated to standard pressure grid of 2m'}\n",
    "\n",
    "ds['N_PROF_NEW'].attrs = {'name':'Sequential Profile Number'}\n",
    "ds['LATITUDE'].attrs = {'name':'Latitude', 'units':'°N'}\n",
    "ds['LONGITUDE'].attrs = {'name':'Longitude', 'units':'°E'}\n",
    "ds['month'].attrs = {'name':'Month'}\n",
    "ds['year'].attrs = {'name':'Year'}\n",
    "ds['MLD'].attrs = {'name':'Mixed Layer Depth', 'units':'m'}\n",
    "\n",
    "ds['CT'].attrs = {'name':'Conservative Temperature', 'units':'°C'}\n",
    "ds['SA'].attrs = {'name':'Absolute Salinity', 'units':'g kg-1'}\n",
    "ds['SIG0'].attrs = {'name':'Potential Density', 'units':'kg m-1', 'notes':'referenced to 0 dbar'}\n",
    "ds['SPICE'].attrs = {'name':'Spiciness', 'units':'kg m-1', 'notes':'referenced to 0 dbar'}                  \n",
    "ds = ds.assign_attrs({\"Fetched_uri\":''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ds_z.LONGITUDE, ds_z.LATITUDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_z.to_netcdf(\"202206_boxes/lon:({},{})_lat:({},{})_ds_z.nc\".format(box_long[0],box_long[1],box_long[2],box_long[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erddap_loader=ArgoDataFetcher(src'erddap',parallel=True,progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaze_loader=ArgoDataFetcher(src='gdac',ftp='https://data-argo.ifremer.fr/',parallel=True,progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_loader=ArgoDataFetcher(src='gdac',ftp='ftp://usgodae.org/pub/outgoing/argo',parallel=True,progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=argo_loader.region(box_1x)\n",
    "print('loading points complete')\n",
    "ds=ds.to_xarray()\n",
    "print('to xarray complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=ds.argo.teos10(['CT','SA','SIG0'])\n",
    "ds=ds.argo.point2profile()\n",
    "print('point to profile complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_box(box,sample_min):\n",
    "    '''Takes latitude/longitude/depth data and a sample rate and returns an xarray with CT, SA, SIG0, and SPICE interpolated to a pressure grid of 2m. \n",
    "    \n",
    "    box: lat/lon in the form: box=[lon_min, lon_max, lat_min, lat_max, depth_min, depth_max]\n",
    "    sample_min: minimum sample rate [m]\n",
    "    '''\n",
    "    \n",
    "    ds=argo_loader.region(box)\n",
    "    print('loading points complete')\n",
    "    \n",
    "    ds=ds.to_xarray()\n",
    "    print('to xarray complete')\n",
    "    \n",
    "    ds=ds.argo.teos10(['CT','SA','SIG0'])\n",
    "    ds=ds.argo.point2profile()\n",
    "    print('point to profile complete')\n",
    "    \n",
    "    ds_interp=get_ds_interp(ds,0,2000,sample_min)\n",
    "    print('interpolation complete')\n",
    "    \n",
    "    ds_interp['SPICE'] = gsw.spiciness0(ds_interp.SA,ds_interp.CT).rename('SPICE')\n",
    "    print('adding spice complete')\n",
    "        \n",
    "    return ds_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_get_box(box_medi,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=argo_loader.region(box_medi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.PSAL.dropna('N_POINTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0,len(ds.N_PROF)):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "methods are also functions, but specific to the class they're applied to\n",
    "class (animals) --> subclass (dogs) --> object (golden retriever)\n",
    "open_mfdataset() from xarray, for opening data in multiple netcdfs\n",
    "1) write loop opening all files yourself, check for PSAL, if not there remove file\n",
    "2) go into open_mfdataset() and see if there's a loop there to exploit instead\n",
    "\n",
    "locally install repo (pip install -e??)\n",
    "uses the code from the local repo instead\n",
    "then make changes to repo: print statement in part of the code we think is happening\n",
    "then work on loops, etc.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_xarray(self, errors: str = \"ignore\"):\n",
    "        \"\"\" Load Argo data and return a :class:`xarray.Dataset`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        errors: str, default='ignore'\n",
    "            Define how to handle errors raised during data URIs fetching:\n",
    "\n",
    "                - 'ignore' (default): Do not stop processing, simply issue a debug message in logging console\n",
    "                - 'silent':  Do not stop processing and do not issue log message\n",
    "                - 'raise': Raise any error encountered\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        :class:`xarray.Dataset`\n",
    "        \"\"\"\n",
    "        if (\n",
    "            len(self.uri) > 50\n",
    "            and isinstance(self.method, str)\n",
    "            and self.method == \"sequential\"\n",
    "        ):\n",
    "            warnings.warn(\n",
    "                \"Found more than 50 files to load, this may take a while to process sequentially ! \"\n",
    "                \"Consider using another data source (eg: 'erddap') or the 'parallel=True' option to improve processing time.\"\n",
    "            )\n",
    "        elif len(self.uri) == 0:\n",
    "            raise DataNotFound(\"No data found for: %s\" % self.indexfs.cname)\n",
    "\n",
    "        # Download data:\n",
    "        ds = self.fs.open_mfdataset(\n",
    "            self.uri, #list of all float files?\n",
    "            method=self.method,\n",
    "            concat_dim=\"N_POINTS\",\n",
    "            concat=True,\n",
    "            preprocess=self._preprocess_multiprof,\n",
    "            progress=self.progress,\n",
    "            errors=errors,\n",
    "            open_dataset_opts={'xr_opts': {'decode_cf': 1, 'use_cftime': 0, 'mask_and_scale': 1}},\n",
    "        )\n",
    "\n",
    "        # Data post-processing:\n",
    "        ds[\"N_POINTS\"] = np.arange(\n",
    "            0, len(ds[\"N_POINTS\"])\n",
    "        )  # Re-index to avoid duplicate values\n",
    "        ds = ds.set_coords(\"N_POINTS\")\n",
    "        ds = ds.sortby(\"TIME\")\n",
    "\n",
    "        # Remove netcdf file attributes and replace them with simplified argopy ones:\n",
    "        ds.attrs = {}\n",
    "        if self.dataset_id == \"phy\":\n",
    "            ds.attrs[\"DATA_ID\"] = \"ARGO\"\n",
    "        if self.dataset_id == \"bgc\":\n",
    "            ds.attrs[\"DATA_ID\"] = \"ARGO-BGC\"\n",
    "        ds.attrs[\"DOI\"] = \"http://doi.org/10.17882/42182\"\n",
    "        ds.attrs[\"Fetched_from\"] = self.server\n",
    "        ds.attrs[\"Fetched_by\"] = getpass.getuser()\n",
    "        ds.attrs[\"Fetched_date\"] = pd.to_datetime(\"now\", utc=True).strftime(\"%Y/%m/%d\")\n",
    "        ds.attrs[\"Fetched_constraints\"] = self.cname()\n",
    "        if len(self.uri) == 1:\n",
    "            ds.attrs[\"Fetched_uri\"] = self.uri[0]\n",
    "        else:\n",
    "            ds.attrs[\"Fetched_uri\"] = \";\".join(self.uri)\n",
    "\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_z.SIG0.values.min(), ds_z.SIG0.values.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_grid = np.linspace(26.6, 28, 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rho = df.interpolate2density_prof(ds_z, rho_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rho.to_netcdf(\"202206_boxes/lon:({},{})_lat:({},{})_ds_rho.nc\".format(box[0],box[1],box[2],box[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load by float (coordinate: distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_ID = 6901265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_z = ff.get_float(float_ID, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_z = ds_z.assign_attrs({\"Fetched_uri\":''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_z.to_netcdf(\"202206_floats/float_ID:({})_ds_z.nc\".format(float_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_z.SIG0.values.min(), ds_z.SIG0.values.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_grid = np.linspace(26.4, 28, 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rho = df.interpolate2density_prof(ds_z, rho_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rho.to_netcdf(\"202206_floats/float_ID:({})_ds_rho.nc\".format(float_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Boxes by Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = np.arange(-180,181,4)\n",
    "lats = np.arange(-90,91,4)\n",
    "\n",
    "boxes=[]\n",
    "\n",
    "for n in range(0,len(lons)-1):\n",
    "    for m in range(0,len(lats-1)):\n",
    "        lon_min = lons[n]\n",
    "        lon_max = lons[n+1]\n",
    "        lat_min = lats[n]\n",
    "        lat_max = lats[n+1]\n",
    "        box_n = np.array([lon_min, lon_max, lat_min, lat_max])\n",
    "        boxes.append(box_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "lons[n+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argopy import IndexFetcher as ArgoIndexFetcher\n",
    "\n",
    "box_bad=[-15,-14,36.5,37]#, '2000-01-01', '2021-06'] # need to remove pressure poinds because the region function for this index fetcher seems a bit different.\n",
    "\n",
    "idx = ArgoIndexFetcher(src='gdac',dataset='phy',mode='standard',\n",
    "                            ftp=\"/swot/SUM05/dbalwada/202203-ArgoData\").region(box_bad).load()\n",
    "idx.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_IDs = [1900041,1900749,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Argo_Nov_24]",
   "language": "python",
   "name": "conda-env-Argo_Nov_24-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
