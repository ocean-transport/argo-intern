{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelization Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will learn how to use dask within xarray to parallelize running code and speed up parts of the Argo analysis. I'll start by running a simple test case (I hope to find) in xarray's documentation. If this work successfully, I will then move on to running the depth-->density interpolation function to see if that comes with speed improvements too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.path import Path\n",
    "import seaborn as sns\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import cartopy.crs as ccrs\n",
    "import cmocean.cm as cmo\n",
    "import gsw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home.ufs/amf2288/argo-intern/funcs')\n",
    "import density_funcs as df\n",
    "import EV_funcs as ef\n",
    "import filt_funcs as ff\n",
    "import plot_funcs as pf\n",
    "import processing_funcs as prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'processing_funcs' from '/home/amf2288/argo-intern/funcs/processing_funcs.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(df)\n",
    "reload(ef)\n",
    "reload(ff)\n",
    "reload(prf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "natl = xr.open_dataset('/swot/SUM05/amf2288/sync-boxes/lon:(-25,-20)_lat:(-70,70)_ds_z.nc')\n",
    "datl = xr.open_dataset('/swot/SUM05/amf2288/sync-boxes/lon:(-25,-20)_lat:(-70,70)_ds_z.nc').chunk({'N_PROF':1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.3 ms, sys: 18.1 ms, total: 61.4 ms\n",
      "Wall time: 57.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.800860854562184"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time float(natl.CT.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 85.5 ms, sys: 66.1 ms, total: 152 ms\n",
      "Wall time: 63.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.800860854562181"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time float(datl.CT.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.36 s, sys: 228 ms, total: 6.59 s\n",
      "Wall time: 6.59 s\n"
     ]
    }
   ],
   "source": [
    "%time natl.CT.groupby('LATITUDE').mean();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.1 s, sys: 96.9 ms, total: 17.2 s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%time datl.CT.groupby('LATITUDE').mean();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay something is not working as expected because the xr ds loaded with dask takes longer than the one loaded without. A few thoughts:\n",
    "- It's possible the chunks are too small, so the overhead added for each calculation overwhelmes any advantage of running in parallel.\n",
    "- Maybe it's not using multiple cores at all: the CPU time is about the same as wall time, which isn't a good sign.\n",
    "- Maybe this isn't a time consuming enough calculation for using dask to make a difference at all?\n",
    "\n",
    "The first thing to look into is definitely the second bullet point. If the processes aren't running oon multiple cores, then nothing else is going to work either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, I went to http://gyre.ldeo.columbia.edu:19999/#menu_users_submenu_cpu;theme=slate;help=true and the natl and datl runs both took right at (or slightly over ) 100%. So I don't think anything is being parallelized. What to try next??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:argo_Aug_23]",
   "language": "python",
   "name": "conda-env-argo_Aug_23-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
